# WebScraper CLI

A simple **command-line web scraper** built with Python.
This tool fetches a webpage, extracts its title and all links, and displays them neatly in the terminal.

This project was built for learning how CLI tools work and the functionalities were not a pritoritiy during developement.

---

## Features

âœ… Fetch any webpage using its URL.

âœ… Automatically adds `https://` if you forget it.

âœ… Extracts and prints:

* Page title
* All hyperlinks (`<a href="...">`) with text

---

## Project Structure

```
web-scrape-cli/
â”‚
â”œâ”€â”€ webscraper/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py              # CLI entry point
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ utils.py        # Helper functions (normalize URL)
â”‚       â”œâ”€â”€ fetch.py        # Fetch page HTML
â”‚       â””â”€â”€ parse.py        # Extract title and links
â”‚
â”œâ”€â”€ pyproject.toml          # Package metadata (for pip install -e .)
â””â”€â”€ README.md
```

---

## Installation

1. **Clone the project:**

   ```bash
   git clone https://github.com/yourusername/web-scrape-cli.git
   cd web-scrape-cli
   ```

2. **(Optional but recommended) Create a virtual environment:**

   ```bash
   python -m venv venv
   venv\Scripts\activate   # On Windows
   source venv/bin/activate  # On macOS/Linux
   ```

3. **Install dependencies and the package in editable mode:**

   ```bash
   pip install -e .
   ```

---

## âš™ï¸ Usage

You can run the scraper in **two ways**:

### Option 1 â€” Using the CLI command (after installation)

```bash
webscraper example.com
```

### Option 2 â€” Using Python directly

```bash
python -m webscraper.cli example.com
```

---

## Example Output

```bash
Scraping content from https://example.com
Page title: Example Domain

All Links:

-> https://www.iana.org/domains/example [More information...]
```

---

## âš ï¸ Notes

* The tool **only scrapes publicly accessible pages**.
* Itâ€™s meant for **educational and non-commercial use**.
* Please respect each websiteâ€™s **robots.txt** and terms of service before scraping.

---

## ğŸ› ï¸ Future Enhancements (M1 Roadmap)

* [ ] Extract images (`--images` flag)
* [ ] Extract meta tags (description, keywords, etc.)
* [ ] Save output to JSON or CSV
* [ ] Handle relative links with `urljoin`

---

## ğŸ“œ License

MIT License Â© 2025 venkat374

---
